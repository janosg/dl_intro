{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78037bc1",
   "metadata": {},
   "source": [
    "# Exercises - 1: Inference with pipeline\n",
    "\n",
    "In this notebook, you will solve example cases from Chapter 1 of the book **\"Natural Language Processing with Transformers: Builiding Language Applications with Hugging Face\"** by Tunstall, von Werra, and Wolf.\n",
    "\n",
    "You will get first experience in using pretrained models for specific tasks, using the *pipelines* API from the Hugging Face Transformes library, which allows you to do inference at a very high level of abstraction.\n",
    "\n",
    "In each exercise, you will first define a *pipeline* for a specific task, using a pretrained model from the Hugging Face models library, and apply the pipeline on an example input text to generate an output.\n",
    "\n",
    "## Resources:\n",
    "- [pipeline documentation](https://huggingface.co/docs/transformers/main_classes/pipelines)\n",
    "- [Hugging Face models library](https://huggingface.co/models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ef806",
   "metadata": {},
   "source": [
    "## The input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1b7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"A miracle is taking place as you read these lines: the squiggles on this page\n",
    "are trans‐ forming into words and concepts and emotions as they navigate their way\n",
    "through your cortex. My thoughts from November 2021 have now successfully invaded your\n",
    "brain. If they manage to catch your attention and survive long enough in this harsh and\n",
    "highly competitive environment, they may have a chance to reproduce again as you share\n",
    "these thoughts with others. Thanks to language, thoughts have become air‐borne and\n",
    "highly contagious brain germs—and no vaccine is coming.\n",
    "\n",
    "Luckily, most brain germs are harmless,1 and a few are wonderfully useful. In fact,\n",
    "humanity’s brain germs constitute two of our most precious treasures: knowledge and\n",
    "culture. Much as we can’t digest properly without healthy gut bacteria, we cannot think\n",
    "properly without healthy brain germs. Most of your thoughts are not actually yours: they\n",
    "arose and grew and evolved in many other brains before they infected you. So if we want\n",
    "to build intelligent machines, we will need to find a way to infect them too.\n",
    "\n",
    "The good news is that another miracle has been unfolding over the last few years:\n",
    "several breakthroughs in deep learning have given birth to powerful language models.\n",
    "Since you are reading this book, you have probably seen some astonishing demos ofthese\n",
    "language models, such as GPT-3, which given a short prompt such as “a frog meets a\n",
    "crocodile” can write a whole story. Although it’s not quite Shakespeare yet, it’s\n",
    "ometimes hard to believe that these texts were written by an artificial neural net‐\n",
    "work. In fact, GitHub’s Copilot system is helping me write these lines: you’ll never now\n",
    "how much I really wrote.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4051265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae75dc",
   "metadata": {},
   "source": [
    "## Task 1 - Text classification\n",
    "\n",
    "1. Define a classifier pipeline using the ` \"distilbert-base-uncased-finetuned-sst-2-english\"` model.\n",
    "\n",
    "2. Apply the pipeline on each paragraph of the input text to extract sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbef014e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9735191464424133}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c10f7e",
   "metadata": {},
   "source": [
    "## Task 2 - Named entity recognition\n",
    "1. Define a named entity recognition (ner) pipeline using the `\"dslim/bert-base-NER-uncased\"` model. Use the same value for `aggregation_strategy`, as in the slides.\n",
    "\n",
    "2. Apply the pipeline on each paragraph of the text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6754e5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.7362914,\n",
       "  'word': 'humanity',\n",
       "  'start': 647,\n",
       "  'end': 655},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.8491372,\n",
       "  'word': 'gpt',\n",
       "  'start': 1354,\n",
       "  'end': 1357},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.8317224,\n",
       "  'word': '3',\n",
       "  'start': 1358,\n",
       "  'end': 1359},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.9769497,\n",
       "  'word': 'shakespeare',\n",
       "  'start': 1472,\n",
       "  'end': 1483},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9260996,\n",
       "  'word': 'github',\n",
       "  'start': 1593,\n",
       "  'end': 1599}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb7d64e",
   "metadata": {},
   "source": [
    "## Task 3: Question answering\n",
    "1. Define a question answering pipeline using the `\"question-answering\"` task and the `\"distilbert-base-cased-distilled-squad\"` model.\n",
    "\n",
    "2. Apply the pipeline on the input text to retrieve answers from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec94c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.027284299954771996,\n",
       "  'start': 999,\n",
       "  'end': 1025,\n",
       "  'answer': 'build intelligent machines'},\n",
       " {'score': 0.047199103981256485,\n",
       "  'start': 1593,\n",
       "  'end': 1616,\n",
       "  'answer': 'GitHub’s Copilot system'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71027bb6",
   "metadata": {},
   "source": [
    "## Task 4: Summarization\n",
    "1. Define a text summarizing pipeline using the `\"summarization\"` task and the `\"sshleifer/distilbart-cnn-6-6\"` model. Use the same additional arguments as in the lecture slides.\n",
    "\n",
    "2. Apply the pipeline on each paragraph of the input text to get a summary of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44aa8562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' A miracle is taking place as you read these lines: the squiggles on this page are transforming into words and concepts and emotions as they navigate their way through your cortex. Thanks to language, thoughts have'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab5c5b61",
   "metadata": {},
   "source": [
    "## Task 5: Translation\n",
    "1. Define a pipeline to translate the input text from English to German, using an appropriate model from the Hugging Face models library.\n",
    "\n",
    "2. Apply the pipeline on the example input text to translate the content to German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365c3c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein Wunder findet statt, wie Sie diese Zeilen lesen: die Squiggles auf dieser Seite transformieren sich in Worte und Konzepte und Emotionen, wie sie ihren Weg durch Ihren Cortex navigieren. Meine Gedanken von November 2021 haben nun erfolgreich in Ihr Gehirn eingedrungen. Wenn sie es schaffen, Ihre Aufmerksamkeit zu fangen und lange genug in diesem harten und stark wettbewerbsfähigen Umfeld überleben, können sie eine Chance haben, wieder zu reproduzieren, wie Sie diese Gedanken mit anderen teilen. Dank der Sprache, Gedanken sind Luft getragen und hoch ansteckende Gehirnkeime geworden – und kein Impfstoff kommt. Zum Glück, die meisten Gehirnkeime sind harmlos,1 und ein paar sind wunderbar nützlich. In der Tat, die Menschheit, Gehirnkeime bilden zwei unserer wertvollsten Schätze: Wissen und Kultur. So viel wie wir nicht richtig verdauen können ohne gesunde Darmbakterien, können wir nicht richtig denken, ohne gesunde Gehirnkeime. Die meisten Ihrer Gedanken sind nicht wirklich Ihre: sie entstanden und wuchsen und entwickelt in vielen anderen Gehirnen, bevor sie Sie infiziert. Also, wenn wir intelligente Maschinen bauen wollen, müssen wir nicht richtig ohne gesunde Darmbakterien verd verd zu verd denken, können wir nicht ohne gesunde Gehirnke Keime denken.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af266d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
