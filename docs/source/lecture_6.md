# Lecture 6

## Topic

In this lecture we extract features from a transformer model and use them to do
classification with sklearn.

## Lecture Slides

```{raw} html
<iframe src="_static/bld/pdfs/lecture_6.pdf" width="700" height="415"></iframe>
```

```{eval-rst}
:download:`Download the slides <_static/bld/pdfs/lecture_6.pdf>`
```

## Exercises


```{toctree}
---
maxdepth: 1
---
bld/notebooks/exercises/exercise_6.ipynb
bld/notebooks/solutions/exercise_6.ipynb
```

## Slides from guest lecture

```{raw} html
<iframe src="_static/pdfs/enacom.pdf" width="700" height="415"></iframe>
```

```{eval-rst}
:download:`Download the slides <_static/pdfs/enacom.pdf>`
```

## Suggested Homework

- Experiment with different classification models and their tuning parameters and try to get a better score

## Additional materials

### Natural Language Processing with transformers

The book [Natural language processing with transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) has served as basis for many of the course materials.

Chapter 2 covers the material of this lecture.

### Videos


<iframe width="560" height="315" src="https://www.youtube.com/embed/AhChOFRegn4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
